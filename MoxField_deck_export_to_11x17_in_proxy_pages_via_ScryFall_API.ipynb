{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#MoxField deck export to 11x17\" proxy pages via ScryFall's API"
      ],
      "metadata": {
        "id": "1MVkW9ZYR8Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Enter your deck's name between the questions marks below (deck_name = \"YOUR DECK NAME HERE\"). Click \"Show code\" if necessary.\n",
        "deck_name = \"Commander - deck name\""
      ],
      "metadata": {
        "id": "7KLUy-exhLbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Copy and paste MoxField Deck Export below. Make sure the quotations marks are on the same lines as your 1st and last card; no extra line break (text = \"\"\"PASTE YOUR DECK HERE\"\"\"). Click \"Show code\" if necessary. Then, on the menubar, select Runtime > Run all and check your Google Drive for the results.\n",
        "text = \"\"\"1 Kambal, Profiteering Mayor (OTJ) 353\n",
        "1 Access Tunnel (STX) 262\n",
        "1 Adeline, Resplendent Cathar (J25) 57\n",
        "1 Aerith Gainsborough (FIN) 4\n",
        "1 Akroma's Memorial (FUT) 159\n",
        "1 Anguished Unmaking (SOI) 242\n",
        "1 Arcane Signet (P30M) 1F\n",
        "1 Auron, Venerated Guardian (FIC) 10\n",
        "1 Avacyn's Memorial (MIC) 69\n",
        "1 Beregond of the Guard (LTC) 93\n",
        "1 Bleachbone Verge (DFT) 250\n",
        "1 Boromir, Warden of the Tower (LTR) 4\n",
        "1 Brightclimb Pathway // Grimclimb Pathway (ZNR) 285\n",
        "1 Cavern of Souls (MM3) 232\n",
        "1 Caves of Koilos (C21) 283\n",
        "1 Cecil, Dark Knight // Cecil, Redeemed Paladin (FIN) 380\n",
        "1 Celestine, the Living Saint (40K) 10\n",
        "1 Command Tower (CMR) 350\n",
        "1 Commissar Severina Raine (40K) 112\n",
        "1 Damnation (MM3) 63\n",
        "1 Dawn's Truce (BLB) 9\n",
        "1 Demonic Tutor (UMA) 93\n",
        "1 Denethor, Ruling Steward (LTR) 198\n",
        "1 Dion, Bahamut's Dominant // Bahamut, Warden of Light (FIN) 16\n",
        "1 Eiganjo Castle (CHK) 275\n",
        "1 Elena, Turk Recruit (FIC) 18\n",
        "1 Flowering of the White Tree (LTR) 15\n",
        "1 General Kudro of Drannith (IKO) 335\n",
        "1 General Leo Cristophe (FIC) 135\n",
        "1 General's Enforcer (IKO) 188\n",
        "1 Generous Gift (CMM) 26\n",
        "1 Godless Shrine (SLD) 128\n",
        "1 Greymond, Avacyn's Stalwart (SLX) 18\n",
        "1 Herald's Horn (C17) 53\n",
        "1 Heroes' Podium (DMC) 185\n",
        "1 Homeward Path (C13) 295\n",
        "1 Horn of Gondor (LTR) 240\n",
        "1 Inkshield (DSC) 221\n",
        "1 Isolated Chapel (DOM) 241\n",
        "1 Jadar, Ghoulcaller of Nephalia (MID) 108\n",
        "1 Jerren, Corrupted Bishop // Ormendahl, the Corrupter (MID) 109\n",
        "1 Kambal, Consul of Allocation (KLD) 183\n",
        "1 Kindred Dominance (CMM) 640\n",
        "1 Loran of the Third Path (BLC) 143\n",
        "1 Loyal Retainers (CMM) 39\n",
        "1 MacCready, Lamplight Mayor (PIP) 108\n",
        "1 Mangara, the Diplomat (CMM) 42\n",
        "1 Marsh Flats (MM3) 239\n",
        "1 Masako the Humorless (CHK) 33\n",
        "1 Nils, Discipline Enforcer (C21) 20\n",
        "1 Orzhov Signet (C21) 254\n",
        "1 Path of Ancestry (PLG21) C3\n",
        "1 Path to Exile (MAR) 4\n",
        "1 Patriarch's Bidding (MH2) 275\n",
        "1 Phyrexian Reclamation (PLST) C15-133\n",
        "3 Plains (HOU) 185\n",
        "3 Plains (AKH) 250\n",
        "1 Plaza of Heroes (DMU) 252\n",
        "1 Ravos, Soultender (C16) 39 *F*\n",
        "1 Reconnaissance (ACR) 82\n",
        "1 Reflecting Pool (CNS) 210\n",
        "1 Relic of Legends (DMU) 236\n",
        "1 Reliquary Tower (PLST) M19-254\n",
        "1 Rogue's Passage (C20) 303\n",
        "1 Rosa, Resolute White Mage (FIN) 555\n",
        "1 Scrubland (VMA) 313\n",
        "1 Secluded Courtyard (NEO) 275\n",
        "1 Sephiroth, Fabled SOLDIER // Sephiroth, One-Winged Angel (FIN) 115\n",
        "1 Shadow, Mysterious Assassin (FIC) 50\n",
        "1 Shizo, Death's Storehouse (CHK) 283\n",
        "1 Sol Ring (DRC) 57\n",
        "1 Squall, SeeD Mercenary (FIN) 402\n",
        "3 Swamp (HOU) 187\n",
        "3 Swamp (AKH) 252\n",
        "1 Syr Konrad, the Grim (DSC) 158\n",
        "1 Tainted Field (C21) 320\n",
        "1 Tainted Sigil (ARB) 83\n",
        "1 Talisman of Hierarchy (MH1) 233\n",
        "1 Teferi's Protection (STA) 11\n",
        "1 Tegan Jovanka (WHO) 28\n",
        "1 Temple of Silence (M21) 255\n",
        "1 Teysa Karlov (SLD) 1235\n",
        "1 Thalia, Heretic Cathar (INR) 44\n",
        "1 Thancred Waters (FIC) 31\n",
        "1 Thought Vessel (DSC) 256\n",
        "1 Tymna the Weaver (FCA) 18\n",
        "1 Unclaimed Territory (PLST) XLN-258\n",
        "1 Unspeakable Symbol (SCG) 79\n",
        "1 Vault of Champions (CMR) 360\n",
        "1 Vault of the Archangel (CLB) 927\n",
        "1 Venat, Heart of Hydaelyn // Hydaelyn, the Mothercrystal (FIN) 329\n",
        "1 Zenos yae Galvus // Shinryu, Transcendent Rival (FIN) 127\"\"\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "IjSPZgf4HYbu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Python libraries and set options\n",
        "\n",
        "# import\n",
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "import shutil\n",
        "\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# options\n",
        "pd.options.mode.copy_on_write = True  # preparing for pandas 3.0 where everything is CoW"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SaB6P4EX7gOU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive and create directories if they don't exist\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# set Google drive directories\n",
        "MTG_DIR = '/gdrive/MyDrive/mtg/'\n",
        "DECKS_DIR = MTG_DIR + 'decks/'\n",
        "\n",
        "# create Google drive directories if they don't exist\n",
        "dirs = [MTG_DIR, DECKS_DIR]\n",
        "for dir in dirs:\n",
        "  Path(dir).mkdir(parents=True, exist_ok=True)\n",
        "  print(f'{dir} exists: {Path(dir).exists()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "LRSVUbg6Mkda",
        "outputId": "b209c2e5-b167-4a74-d7a4-0c5a72265977"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/MyDrive/mtg/ exists: True\n",
            "/gdrive/MyDrive/mtg/decks/ exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Functions\n",
        "\n",
        "def get_moxfield_dataframe(text):\n",
        "    # split text into lines\n",
        "    cards = []\n",
        "    for line in text.split('\\n'):\n",
        "        card_quantity, line = line.split(maxsplit=1)\n",
        "        card_name, line = line.split(\" (\", maxsplit=1)\n",
        "        card_set, line = line.split(\")\", maxsplit=1)\n",
        "\n",
        "        # Moxfield adds ' *F*' to delineate a foiled card, which we don't want\n",
        "        if '*' in line:\n",
        "            card_number, line = line.split(\" *\", maxsplit=1)\n",
        "            card_number = card_number.strip()\n",
        "        else:\n",
        "            card_number = line.strip()\n",
        "        card = [card_quantity, card_name, card_set, card_number]\n",
        "        cards.append(card)\n",
        "\n",
        "    # set column names\n",
        "    columns = ['quantity', 'name', 'mtg_set', 'collector_number']\n",
        "\n",
        "    # create DataFrame\n",
        "    df = pd.DataFrame(cards, columns=columns)\n",
        "\n",
        "    # set columns to appropriate data types\n",
        "    df['quantity'] = df['quantity'].astype(int)\n",
        "    df['name'] = df['name'].astype(str)\n",
        "    df['mtg_set'] = df['mtg_set'].astype(str).str.lower()  # set code to lowercase to match Scryfall data\n",
        "    df['collector_number'] = df['collector_number'].astype(str)\n",
        "\n",
        "    return df\n",
        "\n",
        "def get_card_data_from_scryfall(set_code, collector_number):\n",
        "    url = f'https://api.scryfall.com/cards/{set_code}/{collector_number}'\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    card_data = response.json()\n",
        "\n",
        "    return card_data\n",
        "\n",
        "def get_download_dictionary_from_scryfall(df):\n",
        "    total_cards_to_download = 0\n",
        "    total_double_faced_cards = 0\n",
        "\n",
        "    download_dict = {}\n",
        "\n",
        "    for card in df.itertuples(name='Card'):\n",
        "        set_code = card.mtg_set\n",
        "        collector_number = card.collector_number\n",
        "\n",
        "        for i in range(card.quantity):\n",
        "\n",
        "            # convert i into zero-filled string to use as part of filename\n",
        "            i += 1  # we'll use this as part of our filename so start with 1\n",
        "            i = str(i).zfill(len(str(df['quantity'].max())))\n",
        "\n",
        "            # get data from scryfall (in json form)\n",
        "            scryfall_card_data = get_card_data_from_scryfall(card.mtg_set, card.collector_number)\n",
        "\n",
        "            # double-faced cards don't have images located here so we try here\n",
        "            try:\n",
        "                image_url = scryfall_card_data['image_uris']['png']\n",
        "                total_cards_to_download += 1\n",
        "\n",
        "                # replace double backslashes in card.name with double-dash\n",
        "                # so we don't try to add directories when saving images\n",
        "\n",
        "                # NOTE: this applies to cards with 1 face, but multiple\n",
        "                # names like Adventure cards\n",
        "                if '//' in card.name:\n",
        "                    card_name = card.name.replace('//', '--')\n",
        "                else:\n",
        "                    card_name = card.name\n",
        "\n",
        "                # set image_output_file_name\n",
        "                image_output_file_name = f'{card_name}_{card.mtg_set}-{card.collector_number}_{i}.png'\n",
        "\n",
        "                # add to download_dict\n",
        "                download_dict[image_output_file_name] = image_url\n",
        "\n",
        "            except KeyError:\n",
        "                total_double_faced_cards += 1\n",
        "                total_cards_to_download += 2\n",
        "\n",
        "                for card_face in scryfall_card_data['card_faces']:\n",
        "                    card_name = card_face['name']\n",
        "                    image_url = card_face['image_uris']['png']\n",
        "\n",
        "                    # set image_output_file_name\n",
        "                    image_output_file_name = f'{card_name}_{card.mtg_set}-{card.collector_number}_{i}.png'\n",
        "\n",
        "                    # add to download_dict\n",
        "                    download_dict[image_output_file_name] = image_url\n",
        "\n",
        "    print(f'Total cards to download: {total_cards_to_download}')\n",
        "    if total_double_faced_cards > 0:\n",
        "        print(f'\\tTotal double-faced cards: {total_double_faced_cards}\\n')\n",
        "\n",
        "    return download_dict\n",
        "\n",
        "def download_file(file_url, output_file_path):\n",
        "    # download file\n",
        "    with open(str(output_file_path), 'wb') as out_file:\n",
        "        shutil.copyfileobj(requests.get(file_url, stream = True).raw, out_file)\n",
        "\n",
        "    if not output_file_path.exists():\n",
        "        print(f'Failed to download {file_url} to {output_file_path}\\n')\n",
        "    else:\n",
        "        print(f'Downloaded {file_url} to:\\n\\t{output_file_path}\\n')\n",
        "\n",
        "def is_image_valid(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as image:\n",
        "            image.verify()\n",
        "            return True\n",
        "    except (IOError, SyntaxError):\n",
        "        return False\n",
        "\n",
        "def download_images(deck_name, download_dict):\n",
        "\n",
        "    # set image_output_dir_path on Google Drive and create it if it does not exist\n",
        "    output_dir_path = Path(DECKS_DIR).joinpath(deck_name, '0. Scryfall images')\n",
        "    output_dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(f'Downloading {len(download_dict)} images to:\\n\\t{output_dir_path} . . .')\n",
        "\n",
        "    count = 1\n",
        "    for image_name, image_url in download_dict.items():\n",
        "\n",
        "        # set image_output_file_path\n",
        "        output_file_path = output_dir_path.joinpath(image_name)\n",
        "        if output_file_path.exists():\n",
        "            if is_image_valid(output_file_path):\n",
        "                # print(f'Image {count}\\n\\t{image_name} already exists in:\\n\\t{output_file_path}\\n')\n",
        "                continue  # skip to next iteration of loop\n",
        "        else:\n",
        "            # print(f'Downloading image {count}\\n\\t{image_name} to:\\n\\t{output_file_path} . . .\\n')\n",
        "            download_file(image_url, output_file_path)\n",
        "\n",
        "    image_paths = sorted(output_dir_path.glob('*.png'))\n",
        "    for image_path in image_paths:\n",
        "        if not is_image_valid(image_path):\n",
        "            print(f'!!! ERROR -- {image_path} is not valid! !!!')\n",
        "            break\n",
        "    else:\n",
        "        print(f'\\t{len(image_paths)} images downloaded\\n')\n",
        "\n",
        "    return output_dir_path\n",
        "\n",
        "def process_images(deck_input_dir,\n",
        "                   trim_pixels=12,\n",
        "                   autocontrast_cutoff_percent=(5, 1)\n",
        "                   ):\n",
        "    input_dir_path = Path(deck_input_dir)\n",
        "    output_dir_path = input_dir_path.parent.joinpath('1. Processed images')\n",
        "    output_dir_path.mkdir(parents=True, exist_ok=True)\n",
        "    original_png_paths = sorted(input_dir_path.glob('*.png'))\n",
        "    print(f'Processing images in:\\n\\t{input_dir_path} . . .')\n",
        "\n",
        "    for png_path in original_png_paths:\n",
        "\n",
        "        # get card name in lowercase\n",
        "        card_name = png_path.name.split('-', maxsplit=1)[0].lower()\n",
        "\n",
        "        # open PIL image\n",
        "        image = Image.open(png_path)\n",
        "\n",
        "        # trim pixels off each side\n",
        "        image = ImageOps.crop(image, trim_pixels)\n",
        "\n",
        "        # autocontrast image with tone preservation\n",
        "        if image.mode == 'RGBA':  # autocontrast will fail on (A)lpha channel\n",
        "            # convert to RGB to remove alpha channel\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        image = ImageOps.autocontrast(image,\n",
        "                                      cutoff=autocontrast_cutoff_percent,\n",
        "                                      ignore=None,\n",
        "                                      preserve_tone=True)\n",
        "        output_name = png_path.stem + '.png'\n",
        "        png_output_path = output_dir_path.joinpath(output_name)\n",
        "        image.save(png_output_path)\n",
        "\n",
        "    image_paths = sorted(output_dir_path.glob('*.png'))\n",
        "    for image_path in image_paths:\n",
        "        if not is_image_valid(image_path):\n",
        "            print(f'!!! ERROR -- {image_path} is not valid! !!!')\n",
        "            break\n",
        "    else:\n",
        "        print(f'\\t{len(image_paths)} images processed')\n",
        "\n",
        "    return output_dir_path\n",
        "\n",
        "def get_total_sheets(total_cards, max_cards_per_sheet):\n",
        "    if total_cards > max_cards_per_sheet:\n",
        "        total_sheets = total_cards // max_cards_per_sheet\n",
        "        if total_cards % max_cards_per_sheet > 0:\n",
        "            total_sheets += 1\n",
        "    else:\n",
        "        total_sheets = 1\n",
        "    return total_sheets\n",
        "\n",
        "def layout_images(image_paths,\n",
        "                  num_of_columns,\n",
        "                  num_of_rows,\n",
        "                  image_width_px,\n",
        "                  image_height_px\n",
        "                  ):\n",
        "    image_size = (num_of_columns * image_width_px, num_of_rows * image_height_px)\n",
        "    image_grid = Image.new('RGB', image_size, color='white')\n",
        "    count = 0\n",
        "    # Paste in each image\n",
        "    for i_row in range(num_of_rows):\n",
        "        for i_column in range(num_of_columns):\n",
        "            left = i_column * image_width_px\n",
        "            right = left + image_width_px\n",
        "            upper = i_row * image_height_px\n",
        "            lower = upper + image_height_px\n",
        "            bbox = (left, upper, right, lower)\n",
        "            try:\n",
        "                image = Image.open(image_paths[count])\n",
        "            except:\n",
        "                break\n",
        "            image_grid.paste(image, bbox)\n",
        "            count += 1\n",
        "    return image_grid\n",
        "\n",
        "def make_proxy_pages(input_dir, ppi=300, paper_size='11x17'):\n",
        "    if paper_size == '11x17':\n",
        "        max_cards_per_sheet = 18\n",
        "        paper_width_in = 17\n",
        "        paper_height_in = 11\n",
        "        max_columns = 6\n",
        "        max_rows = 3\n",
        "        paper_orientation = 'horizontal'\n",
        "    elif paper_size == '8.5x11':\n",
        "        max_cards_per_sheet = 12\n",
        "        paper_width_in = 11\n",
        "        paper_height_in = 8.5\n",
        "        max_columns = 5\n",
        "        max_rows = 2\n",
        "        paper_orientation = 'horizontal'\n",
        "\n",
        "    # get sorted list of processed PNG images\n",
        "    image_paths = sorted(Path(input_dir).glob('*.png'))\n",
        "\n",
        "    image = Image.open(image_paths[0])\n",
        "    image_width_px, image_height_px = image.size\n",
        "\n",
        "    # calculate number of sheets\n",
        "    total_cards = len(image_paths)\n",
        "    total_sheets = get_total_sheets(total_cards, max_cards_per_sheet)\n",
        "\n",
        "    # get number of remainder cards for the last page\n",
        "    remainder_cards = total_cards % max_cards_per_sheet\n",
        "\n",
        "    # create and save proxy sheets\n",
        "    for i_sheet in range(total_sheets):\n",
        "        i_sheet += 1\n",
        "\n",
        "        # set number_of_cards\n",
        "        if total_sheets == 1:  # we have less than fits on 1 sheet\n",
        "            number_of_cards = total_cards\n",
        "        elif i_sheet == total_sheets and remainder_cards != 0:  # we have remainder cards on last sheet\n",
        "            number_of_cards = remainder_cards\n",
        "        else:  # we lucked out and printed a perfect number cards for our page size (it evernly divides)\n",
        "            number_of_cards = max_cards_per_sheet\n",
        "\n",
        "        print(f'i_sheet: {i_sheet}')\n",
        "        print(f'\\tnumber_of_cards: {number_of_cards}')\n",
        "\n",
        "        # convert inches measurements to pixels\n",
        "        paper_width_px = int(paper_width_in * ppi)\n",
        "        paper_height_px = int(paper_height_in * ppi)\n",
        "\n",
        "        print(f'\\tExpected paper size:\\n\\t\\t{paper_width_in} x {paper_height_in} @ {ppi} inches\\n\\t\\t{paper_width_px} x {paper_height_px} pixels')\n",
        "\n",
        "        print(f'Processing . . . Sheet {i_sheet}\\n\\tTotal cards: {number_of_cards}')\n",
        "\n",
        "        # get images for grid from png_paths then remove them from list\n",
        "        images_for_grid = image_paths[:number_of_cards]\n",
        "        image_paths = image_paths[number_of_cards:]\n",
        "\n",
        "        image_grid = layout_images(images_for_grid,\n",
        "                                    max_columns,\n",
        "                                    max_rows,\n",
        "                                    image_width_px,\n",
        "                                    image_height_px\n",
        "                                    )\n",
        "\n",
        "        grid_width, grid_height = image_grid.size\n",
        "\n",
        "        # default orienation is horizontal with 36\" wide roll paper\n",
        "        if paper_orientation == 'horizontal':\n",
        "            add_width_px = paper_width_px - grid_width\n",
        "            add_height_px = paper_height_px - grid_height\n",
        "        else:  # it's vertical\n",
        "            add_width_px = paper_width_px - grid_height\n",
        "            add_height_px = paper_height_px - grid_width\n",
        "\n",
        "        border = (add_width_px // 2,\n",
        "                    add_height_px // 2,\n",
        "                    add_width_px // 2,\n",
        "                    add_height_px // 2,\n",
        "                    )\n",
        "\n",
        "        image_grid = ImageOps.expand(image_grid.copy(), border=border, fill=(255, 255, 255))\n",
        "\n",
        "        final_width_px, final_height_px = image_grid.size\n",
        "\n",
        "        if final_width_px != paper_width_px:\n",
        "            if final_width_px > paper_width_px:\n",
        "                print(f'ERROR: final_width_px {final_width_px} > paper_width_px {paper_width_px}')\n",
        "                continue  # on to next page loop\n",
        "            elif final_width_px < paper_width_px:\n",
        "                add_width_px = paper_width_px - final_width_px\n",
        "\n",
        "                # if we're just 1 pixel off, then add it to the end of the document\n",
        "                if add_width_px == 1:\n",
        "                    border = (0, 0, add_width_px, 0)\n",
        "                    image_grid = ImageOps.expand(image_grid.copy(), border=border, fill=(255, 255, 255))\n",
        "\n",
        "        if final_height_px != paper_height_px:\n",
        "            if final_height_px > paper_height_px:\n",
        "                print(f'ERROR: final_height_px {final_height_px} > paper_height_px {paper_height_px}\\n')\n",
        "                continue  # on to next page loop\n",
        "            elif final_height_px < paper_height_px:\n",
        "                add_height_px = paper_height_px - final_height_px\n",
        "\n",
        "                # if we're just 1 pixel off, then add it to the end of the document\n",
        "                if add_height_px == 1:\n",
        "                    border = (0, 0, 0, add_height_px)\n",
        "                    image_grid = ImageOps.expand(image_grid.copy(), border=border, fill=(255, 255, 255))\n",
        "\n",
        "        final_width_px, final_height_px = image_grid.size\n",
        "\n",
        "        print(f'\\tFinal paper size: {final_width_px} x {final_height_px} pixels\\n')\n",
        "\n",
        "        output_dir_path = Path(input_dir).parent.joinpath('2. Proxy Sheets')\n",
        "        output_dir_path.mkdir(parents=True, exist_ok=True)\n",
        "        proxy_sheet_name = f'{output_dir_path.parent.name}_{paper_orientation}_proxy-sheet_{str(i_sheet).zfill(len(str(total_sheets)))}.jpg'\n",
        "        proxy_sheet_path = output_dir_path.joinpath(proxy_sheet_name)\n",
        "        image_grid.save(proxy_sheet_path, dpi=(ppi, ppi), keeprgb=True)\n",
        "        if proxy_sheet_path.exists():\n",
        "            print(f'Saved proxy sheet to:\\n\\t{proxy_sheet_path}\\n')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Y4tAgyGnDxQy"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Parse MoxField deck export into Pandas DataFrame, create download dictionary with links to scryfall, download then process the card images, create proxy pages for 11\"x17\" paper\n",
        "df = get_moxfield_dataframe(text)\n",
        "download_dict = get_download_dictionary_from_scryfall(df)\n",
        "output_dir = download_images(deck_name, download_dict)\n",
        "output_dir = process_images(output_dir)\n",
        "make_proxy_pages(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "2XPXA0l9IFGa",
        "outputId": "825cd0a9-8034-41fb-c366-e87a523b98cc"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total cards to download: 107\n",
            "\tTotal double-faced cards: 7\n",
            "\n",
            "Downloading 107 images to:\n",
            "\t/gdrive/MyDrive/mtg/decks/commander - like humans do by SeraphSix/0. Scryfall images . . .\n",
            "\t107 images downloaded\n",
            "\n",
            "Processing images in:\n",
            "\t/gdrive/MyDrive/mtg/decks/commander - like humans do by SeraphSix/0. Scryfall images . . .\n",
            "\t107 images processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fk1mQaSlONrK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}